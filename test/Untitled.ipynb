{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0edcb891-fef0-4b72-a0b7-434a3b7ecd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../code/')\n",
    "\n",
    "from loss.BCELoss import BCELoss\n",
    "from loss.CELoss import CELoss\n",
    "from loss.MSELoss import MSELoss\n",
    "from activation.TanH import TanH\n",
    "from activation.Sigmoide import Sigmoide\n",
    "from activation.Softmax import Softmax\n",
    "from Linear import Linear\n",
    "from Optim import SGD\n",
    "from Sequentiel import Sequentiel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import make_classification\n",
    "from mltools import plot_data, plot_frontiere, make_grid, gen_arti\n",
    "from termcolor import colored\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97b49c0d-b649-4553-86b1-afba8d3b2ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_usps(fn):\n",
    "    with open(fn,\"r\") as f:\n",
    "        f.readline()\n",
    "        data = [[float(x) for x in l.split()] for l in f if len(l.split())>2]\n",
    "    tmp=np.array(data)\n",
    "    return tmp[:,1:],tmp[:,0].astype(int)\n",
    "\n",
    "def test_autoEncoder_debruitage(p=0, max_iter = 2):\n",
    "    nom_fichier_train =  \"../data/mnist_train.csv\"\n",
    "    nom_fichier_test =  \"../data/mnist_test.csv\"\n",
    "    data_train =  pd.read_csv(nom_fichier_train).to_numpy()\n",
    "    data_test =  pd.read_csv(nom_fichier_test).to_numpy()\n",
    "    alltrainx,alltrainy = data_train[:,1:].astype('float32') , data_train[:,0]\n",
    "    alltestx, alltesty = data_test[:,1:].astype('float32') , data_test[:,0]\n",
    "    \n",
    "    alltrainx /= 255\n",
    "    alltestx /= 255\n",
    "\n",
    "    # print(datax.shape)\n",
    "\n",
    "    #bruit \n",
    "    noise_factor = p\n",
    "    X_train_noise = alltrainx + noise_factor * \\\n",
    "        tf.random.normal(shape=datax.shape).numpy()\n",
    "    \n",
    "    n = 7\n",
    "    \n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(X_train_noise[i].reshape(16, 16))\n",
    "        plt.gray()\n",
    "    plt.show()\n",
    "\n",
    "    # # Ajout bruit\n",
    "    # p = 0.8\n",
    "    # X_train_noise = alltrainx + p * np.random.normal(loc=0.0, scale=0.5, size=alltrainx.shape)\n",
    "    # X_test_noise = alltestx + p * np.random.normal(loc=0.0, scale=0.5, size=alltestx.shape)\n",
    "    \n",
    "    iteration = max_iter\n",
    "    eps = 1e-3\n",
    "    batch_size = 20\n",
    "\n",
    "    l1 = Linear(256, 100)\n",
    "    l2 = Linear(100, 10)\n",
    "    l3 = Linear(10, 100)\n",
    "    l4 = Linear(100, 256)\n",
    "    l3._parameters = l2._parameters.T.copy()\n",
    "    l4._parameters = l1._parameters.T.copy()\n",
    "\n",
    "    encoder = Sequentiel(l1, TanH(), l2, TanH())\n",
    "    decoder = Sequentiel(l3, TanH(), l4, Sigmoide())\n",
    "    model = Sequentiel(encoder, decoder)\n",
    "    loss = BCELoss()\n",
    "    opt = SGD(model, loss, X_train_noise, X_train_noise,\n",
    "              batch_size, nbIter=iteration, eps=eps)\n",
    "    opt.update()\n",
    "\n",
    "    predict = model.forward(X_train_noise)\n",
    "    losss = loss.forward(datax,predict)\n",
    "    print(\"erreur\",losss.mean())\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(predict[i].reshape(16, 16))\n",
    "        plt.gray()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362bc93c-9011-4389-99d9-6e736f41b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_autoEncoder_debruitage(p=0, max_iter = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a6db4-5cb6-4ce5-b04e-223ee5c97810",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_autoEncoder_debruitage(p=0.2, max_iter = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b83560-afed-4dbc-b66c-85d6d13391c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_autoEncoder_debruitage(p=0.4, max_iter = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58bdf39-b03f-497c-afd4-763894e6591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_autoEncoder_debruitage(p=0.6, max_iter = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6736b4cb-ee0f-4759-8cbd-136d05fba0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_autoEncoder_debruitage(p=0.8, max_iter = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c025f615-f93b-47ba-9fc5-c0d274ca4df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_autoEncoder_debruitage(p=1, max_iter = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a7471a-0941-4187-99b2-982c70acda86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
