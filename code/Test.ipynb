{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6e170ee-a4c8-4cb3-8763-6032450017ec",
   "metadata": {},
   "source": [
    "# Test Encodage Decodage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd162223-c0b6-4d95-bd16-0411b134bc7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16540/4012578185.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# from loss import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBCELoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCELoss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCELoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMSELoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'loss'"
     ]
    }
   ],
   "source": [
    "## Import des librairies\n",
    "import sys\n",
    "sys.path.insert(1, '/code/')\n",
    "\n",
    "# from loss import *\n",
    "\n",
    "from loss.BCELoss import BCELoss\n",
    "from loss.CELoss import CELoss\n",
    "from loss.MSELoss import MSELoss\n",
    "from activation.TanH import TanH\n",
    "from activation.Sigmoide import Sigmoide\n",
    "from activation.Softmax import Softmax\n",
    "from Linear import Linear\n",
    "from Optim import SGD\n",
    "from Sequentiel import Sequentiel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import make_classification\n",
    "from mltools import plot_data, plot_frontiere, make_grid, gen_arti\n",
    "from termcolor import colored\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.insert(1, '../code/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260f348e-ae40-490d-95d9-4c4380f9aaed",
   "metadata": {},
   "source": [
    "## debruitage des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a760ff0f-09cd-4db7-88ad-4a3093f874ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_autoEncoder_debruitage(p=0, max_iter = 2):\n",
    "    uspsdatatrain = \"../data/USPS_train.txt\"\n",
    "    uspsdatatest = \"../data/USPS_test.txt\"\n",
    "    alltrainx, alltrainy = load_usps(uspsdatatrain)\n",
    "    alltestx, alltesty = load_usps(uspsdatatest)\n",
    "\n",
    "    datax = alltrainx\n",
    "    # print(datax.shape)\n",
    "\n",
    "    #bruit \n",
    "    noise_factor = p\n",
    "    X_train_noise = alltrainx + noise_factor * \\\n",
    "        tf.random.normal(shape=datax.shape).numpy()\n",
    "    \n",
    "    \n",
    "    n = 5\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(X_train_noise[i].reshape(16, 16))\n",
    "        plt.gray()\n",
    "    plt.show()\n",
    "\n",
    "    # # Ajout bruit\n",
    "    # p = 0.8\n",
    "    # X_train_noise = alltrainx + p * np.random.normal(loc=0.0, scale=0.5, size=alltrainx.shape)\n",
    "    # X_test_noise = alltestx + p * np.random.normal(loc=0.0, scale=0.5, size=alltestx.shape)\n",
    "    \n",
    "    iteration = max_iter\n",
    "    eps = 1e-3\n",
    "    batch_size = 20\n",
    "\n",
    "    l1 = Linear(256, 100)\n",
    "    l2 = Linear(100, 10)\n",
    "    l3 = Linear(10, 100)\n",
    "    l4 = Linear(100, 256)\n",
    "    l3._parameters = l2._parameters.T.copy()\n",
    "    l4._parameters = l1._parameters.T.copy()\n",
    "\n",
    "    encoder = Sequentiel(l1, TanH(), l2, TanH())\n",
    "    decoder = Sequentiel(l3, TanH(), l4, Sigmoide())\n",
    "    model = Sequentiel(encoder, decoder)\n",
    "    loss = BCELoss()\n",
    "    opt = SGD(model, loss, X_train_noise, X_train_noise,\n",
    "              batch_size, nbIter=iteration, eps=eps)\n",
    "    opt.update()\n",
    "\n",
    "    predict = model.forward(X_train_noise)\n",
    "    losss = loss.forward(datax,predict)\n",
    "    print(\"erreur\",losss.mean())\n",
    "\n",
    "    n = 5\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(predict[i].reshape(16, 16))\n",
    "        plt.gray()\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
